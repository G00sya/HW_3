{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f802c980-0f2c-4ee8-b494-ff639305d5c6",
   "metadata": {},
   "source": [
    "# Summarization Model Demonstration\n",
    "\n",
    "Notebook should be run in our poetry environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0388bae-9350-4a26-ae9e-bad5df76c809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nur/.cache/pypoetry/virtualenvs/ml-hw3-6sem-gCt_yKT6-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import torch\n",
    "from src.inference import load_model_and_data, batch_predict, interactive_predict\n",
    "from src.utils.device import setup_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a00bd6cf-2664-4550-86ed-c264b630b559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nur/.cache/pypoetry/virtualenvs/ml-hw3-6sem-gCt_yKT6-py3.12/lib/python3.12/site-packages/gensim/models/keyedvectors.py:551: UserWarning: Adding single vectors to a KeyedVectors which grows by one each time can be costly. Consider adding in batches or preallocating to the required size.\n",
      "  warnings.warn(\n",
      "Creating datasets: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 74278/74278 [00:14<00:00, 5041.28it/s]\n",
      "2025-05-25 22:01:21,407 - prepare_data - INFO - Train size = 63136\n",
      "2025-05-25 22:01:21,408 - prepare_data - INFO - Test size = 11142\n",
      "2025-05-25 22:01:21,869 - prepare_data - INFO - Vocab size = 500004\n"
     ]
    }
   ],
   "source": [
    "DEVICE = setup_device()\n",
    "MODEL_PATH = str(Path(os.getcwd()).parent / \"model/model-30_epochs-without_unk_and_punctuation_all_data.pt\")\n",
    "EMBEDDING_PATH = str(Path(os.getcwd()).parent / \"embeddings/navec_hudlit_v1_12B_500K_300d_100q.tar\")\n",
    "DATA_PATH = str(Path(os.getcwd()).parent / \"data/raw/news.csv\")\n",
    "\n",
    "try:\n",
    "    model, data = load_model_and_data(MODEL_PATH, device=DEVICE, embedding_path=EMBEDDING_PATH, data_path=DATA_PATH)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    model, data = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca7794eb-d247-4ce6-89a7-6885991aee5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Predictions:\n",
      "\n",
      "--- Example 1 ---\n",
      "Input: Пластик произвел революцию в пищевой упаковке\n",
      "Prediction: <unk> сша снизил цены на нефть\n",
      "\n",
      "--- Example 2 ---\n",
      "Input: Ученые обнаружили микрочастицы пластика в чайных пакетиках\n",
      "Prediction: индекс nasdaq вырос на <unk>\n",
      "\n",
      "--- Example 3 ---\n",
      "Input: Новые исследования показывают опасность нанопластика\n",
      "Prediction: в сети появился трейлер нового ледникового периода <unk>\n",
      "\n",
      "--- Example 4 ---\n",
      "Input: В Москве сегодня хорошая погода, светит солнце и температура около 25 градусов.\n",
      "Prediction: в москве нашли <unk> <unk>\n",
      "\n",
      "--- Example 5 ---\n",
      "Input: Книга рассказывает о приключениях молодого волшебника в школе магии.\n",
      "Prediction: в сети появился трейлер нового ледникового периода <unk>\n",
      "\n",
      "--- Example 6 ---\n",
      "Input: Президент объявил о новых экономических реформах для поддержки малого бизнеса.\n",
      "Prediction: в сети появился трейлер нового ледникового периода <unk>\n",
      "\n",
      "--- Example 7 ---\n",
      "Input: Команда выиграла чемпионат, показав отличную игру на протяжении всего сезона.\n",
      "Prediction: <unk> не нашел выступление на <unk>\n",
      "\n",
      "--- Example 8 ---\n",
      "Input: Концерт привлек тысячи зрителей и стал одним из самых ярких событий года.\n",
      "Prediction: в москве пройдет выставка современного искусства\n",
      "\n",
      "--- Example 9 ---\n",
      "Input: Ученые разрабатывают новые методы лечения рака, основанные на последних достижениях в генетике.\n",
      "Prediction: в сети появился трейлер нового ледникового периода <unk>\n",
      "\n",
      "--- Example 10 ---\n",
      "Input: Компания представила новую модель смартфона с улучшенными характеристиками и функциями.\n",
      "Prediction: <unk> не нашел выступление на <unk>\n",
      "\n",
      "Predictions saved to predictions.json\n"
     ]
    }
   ],
   "source": [
    "test_texts = [\n",
    "    \"Пластик произвел революцию в пищевой упаковке\",\n",
    "    \"Ученые обнаружили микрочастицы пластика в чайных пакетиках\",\n",
    "    \"Новые исследования показывают опасность нанопластика\",\n",
    "    \"В Москве сегодня хорошая погода, светит солнце и температура около 25 градусов.\",\n",
    "    \"Книга рассказывает о приключениях молодого волшебника в школе магии.\",\n",
    "    \"Президент объявил о новых экономических реформах для поддержки малого бизнеса.\",\n",
    "    \"Команда выиграла чемпионат, показав отличную игру на протяжении всего сезона.\",\n",
    "    \"Концерт привлек тысячи зрителей и стал одним из самых ярких событий года.\",\n",
    "    \"Ученые разрабатывают новые методы лечения рака, основанные на последних достижениях в генетике.\",\n",
    "    \"Компания представила новую модель смартфона с улучшенными характеристиками и функциями.\"\n",
    "]\n",
    "\n",
    "if model and data:\n",
    "    output_file = \"predictions.json\"\n",
    "    try:\n",
    "        predictions, results = batch_predict(model, data, test_texts, device=DEVICE, output_file=output_file)\n",
    "\n",
    "        print(\"Batch Predictions:\")\n",
    "        for i, (text, pred) in enumerate(zip(test_texts, predictions)):\n",
    "            print(f\"\\n--- Example {i+1} ---\")\n",
    "            print(f\"Input: {text}\")\n",
    "            print(f\"Prediction: {pred}\")\n",
    "\n",
    "        print(f\"\\nPredictions saved to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during batch prediction: {e}\")\n",
    "else:\n",
    "    print(\"Model not loaded, skipping batch prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c5188a7-e25f-4c91-baca-05c516e2f569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter text to summarize (or commands):\n",
      "- 'debug' to toggle verbose mode\n",
      "- 'quit' to exit\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Сегодня погода отличная, поэтому все вышли прогуливать своих собак. А дети на улице играют во всякие игры.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary: в москве открылся памятник гансу христиану андерсену\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  quit\n"
     ]
    }
   ],
   "source": [
    "# Interactive prediction\n",
    "if model and data:\n",
    "    try:\n",
    "        interactive_predict(model, data, DEVICE)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during interactive prediction: {e}\")\n",
    "else:\n",
    "    print(\"Model not loaded, skipping interactive prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba6758e-4471-49da-b557-6946737880c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
